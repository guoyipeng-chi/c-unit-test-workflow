# vLLM远程服务器配置示例
# 复制此文件为 .env 或直接设置环境变量

# ============ vLLM API配置 ============

# 方式1: 本地部署（默认）
# export VLLM_API_BASE=http://localhost:8000

# 方式2: 局域网远程服务器
# export VLLM_API_BASE=http://192.168.1.100:8000

# 方式3: 云服务器（公网IP）
# export VLLM_API_BASE=http://your-server.com:8000

# 方式4: 云服务器（带端口转发）
# export VLLM_API_BASE=http://123.45.67.89:8000

# 当前配置（取消注释以使用）
export VLLM_API_BASE=http://localhost:8000

# ============ 模型配置 ============
export VLLM_MODEL=qwen-coder

# ============ API认证（如果需要）============
# export VLLM_API_KEY=your-api-key-here

# ============ 超时配置 ============
export VLLM_TIMEOUT=120

# ============ 使用方法 ============
# 
# Linux/Mac:
#   source vllm_config.env
#   python quickstart_llm.py --generate
#
# Windows PowerShell:
#   $env:VLLM_API_BASE="http://192.168.1.100:8000"
#   python quickstart_llm.py --generate
#
# Windows CMD:
#   set VLLM_API_BASE=http://192.168.1.100:8000
#   python quickstart_llm.py --generate
